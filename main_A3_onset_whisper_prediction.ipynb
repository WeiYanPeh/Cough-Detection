{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 22:07:58.778728: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-21 22:07:58.794047: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-21 22:07:58.810494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-21 22:07:58.815200: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-21 22:07:58.827415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-21 22:08:00.250541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 22:08:01.826824: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "!TF_ENABLE_ONEDNN_OPTS=0\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import datasets\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import json\n",
    "import csv\n",
    "import pathlib\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import xgboost as xgb\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from pydub import AudioSegment # sudo apt install ffmpeg\n",
    "%matplotlib inline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder, \n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    scale\n",
    "    )\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, \n",
    "    train_test_split, \n",
    "    RepeatedStratifiedKFold, \n",
    "    cross_val_score, \n",
    "    KFold,\n",
    "    StratifiedKFold\n",
    "    ) \n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score\n",
    "    )\n",
    "\n",
    "\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "from transformers import WhisperModel, WhisperFeatureExtractor, AdamW\n",
    "# from transformers import WhisperEncoder\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "from functions_whisper_model import SpeechClassificationDataset, SpeechClassifier, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets = [\n",
    "    # ['fsdkaggle'],    # 2% cough Counter({0: 1570, 1: 30})\n",
    "    # ['virufy'],       # 100% cough Counter({1: 121})\n",
    "    # ['esc50'],        # 2% cough Counter({0: 1960, 1: 40})\n",
    "    # ['coughvid'],     # 30% cough Counter({1: 19777, 0: 10267})\n",
    "    # ['coswara'],      # 25% cough Counter({0: 18914, 1: 5408})\n",
    "    ['coswara', 'coughvid', 'esc50', 'fsdkaggle', 'virufy'], \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "coswara, coughvid, esc50, fsdkaggle, virufy\n",
      "Window Length: 1\n",
      "############################################################\n",
      "(30151, 6)\n",
      "Counter({'coughvid': 751, 'coswara': 733, 'fsdkaggle': 278, 'esc50': 226, 'virufy': 12})\n",
      "Counter({1: 1000, 0: 1000})\n",
      "Train: 1400\n",
      "Val  : 300\n",
      "Test : 300\n",
      "Epoch 1/1, Batch 20/44, Train Loss: 0.6431, Run-time: 105.247s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for window_length in [\n",
    "    # 0.1, 0.2, 0.3, \n",
    "    # 0.5, 0.7, \n",
    "    1\n",
    "    ]:\n",
    "    df_results = []\n",
    "    for datasets_name in list_datasets:\n",
    "        datasets_name.sort()\n",
    "        print('')\n",
    "        print('#'*60)\n",
    "        print(', '.join(datasets_name))\n",
    "        print(f'Window Length: {window_length}')\n",
    "        print('#'*60)\n",
    "        \n",
    "        dataset_str = '_'.join(datasets_name)\n",
    "\n",
    "        if not os.path.exists(f'Results_Onset/Model_Whisper_Onset/{dataset_str}'):\n",
    "            os.makedirs(f'Results_Onset/Model_Whisper_Onset/{dataset_str}')\n",
    "            \n",
    "        path_model_save = f'Results_Onset/Model_Whisper_Onset/{dataset_str}/whisper_best_model_{window_length}s.pt'\n",
    "\n",
    "        ################################################################\n",
    "        # Load Data\n",
    "        ################################################################\n",
    "        df_all = pd.DataFrame()\n",
    "        for dataset in datasets_name:\n",
    "            df = pd.read_csv(f'Results_Onset/Sliced_Wav_Onset/dataset_{dataset}_{window_length}s_onset.csv')\n",
    "            df_all = pd.concat([df_all, df], axis=0)\n",
    "        df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "        ################################################################\n",
    "        # Prepare Data\n",
    "        ################################################################        \n",
    "        df_all['filepath'] = '/home/l083319/Cough_Related/' + df_all['filepath']\n",
    "        df_all = df_all[df_all['mean_amplitude'] > 0.005].reset_index(drop=True)\n",
    "\n",
    "        for col in ['prob', 'status', 'age', 'Unnamed: 0', 'gender', 'mean_amplitude']:\n",
    "            if col in df_all.columns:\n",
    "                df_all = df_all.drop([col], axis=1)\n",
    "        \n",
    "        audio_df = df_all.rename(columns={\n",
    "            'label': 'classID', \n",
    "            'filepath': 'full_path',\n",
    "        })\n",
    "        \n",
    "        print(audio_df.shape)\n",
    "        audio_df = audio_df.sample(frac=1).groupby('classID').head(1000).reset_index(drop=True)\n",
    "        \n",
    "        # print(audio_df)\n",
    "        print(Counter(audio_df['dataset']))\n",
    "        print(Counter(audio_df['classID']))\n",
    "        \n",
    "        train_df, temp_df = train_test_split(audio_df, test_size=0.3, random_state=42)\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "        \n",
    "        print('Train:', len(train_df))\n",
    "        print('Val  :', len(val_df))\n",
    "        print('Test :', len(test_df))\n",
    "        \n",
    "        train_audio_dataset = datasets.Dataset.from_dict({\n",
    "            \"audio\": train_df[\"full_path\"].tolist(),\n",
    "            \"labels\": train_df[\"classID\"].tolist()    \n",
    "            }).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "        \n",
    "        test_audio_dataset = datasets.Dataset.from_dict({\n",
    "            \"audio\": test_df[\"full_path\"].tolist(),\n",
    "            \"labels\": test_df[\"classID\"].tolist()\n",
    "            }).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "        \n",
    "        val_audio_dataset = datasets.Dataset.from_dict({\n",
    "            \"audio\": val_df[\"full_path\"].tolist(),\n",
    "            \"labels\": val_df[\"classID\"].tolist()\n",
    "            }).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "        ################################################################\n",
    "        # Load Whisper\n",
    "        ################################################################\n",
    "        model_checkpoint = \"openai/whisper-base\"\n",
    "        processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
    "        whisper_model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "        encoder = whisper_model.encoder  # this is the encoder module\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        train_dataset = SpeechClassificationDataset(train_audio_dataset, processor, encoder)\n",
    "        test_dataset = SpeechClassificationDataset(test_audio_dataset, processor, encoder)\n",
    "        val_dataset = SpeechClassificationDataset(val_audio_dataset, processor, encoder)\n",
    "        \n",
    "        batch_size = 32\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        num_labels = 2\n",
    "        \n",
    "        model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "        optimizer = AdamW(model.parameters(), lr=2e-5, betas=(0.9, 0.999), eps=1e-08)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "        num_epochs = 1\n",
    "        \n",
    "        # state_dict = torch.load('/home/l083319/Cough_Related/Results/Model/whisper_best_model.pt')\n",
    "        # encoder = WhisperModel.from_pretrained(model_checkpoint)\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # num_labels = 2\n",
    "        # model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "        # model.load_state_dict(state_dict)\n",
    "\n",
    "        ################################################################\n",
    "        # Train Whisper\n",
    "        ################################################################\n",
    "        start = time.time() \n",
    "        train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, path_model_save)\n",
    "        end = time.time() \n",
    "        \n",
    "        print(f\"Total runtime of the program is {round(end - start, 3)}s\") \n",
    "        print('Training Done!')\n",
    "\n",
    "        ################################################################\n",
    "        # Test Whisper\n",
    "        ################################################################\n",
    "        print('Load Whisper Model')\n",
    "\n",
    "        # Create a new instance of the model and load the state dictionary\n",
    "        num_labels = 2\n",
    "        state_dict = torch.load(path_model_save)\n",
    "        model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        print('Evaluate Data')\n",
    "        _, _, _, all_labels, all_preds, all_probs = evaluate(model, test_loader, optimizer, criterion, device)\n",
    "        \n",
    "        print(classification_report(all_labels, all_preds))\n",
    "        print('ACC:', accuracy_score(all_labels, all_preds))\n",
    "        print('Training Done!')\n",
    "    \n",
    "        y_test = all_labels\n",
    "        y_predict = all_preds\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_predict)\n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        print(cm)\n",
    "        \n",
    "        lr_fpr, lr_tpr, _ = roc_curve(y_test, all_probs[:,1])\n",
    "        roc_auc = auc(lr_fpr, lr_tpr)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, all_probs[:,1])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        pre = precision_score(y_test, y_predict)\n",
    "        rec = recall_score(y_test, y_predict)\n",
    "        f1 = f1_score(y_test, y_predict)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "        spe = tn / (tn + fp)\n",
    "        sen = rec\n",
    "        \n",
    "        columns = ['dataset', 'dataset_counter', 'label_count', 'window_length',\n",
    "                   'model',\n",
    "                   'acc', 'sen', 'spe', 'pre', 'rec', 'f1', 'auc', 'auprc', 'cm']  \n",
    "        \n",
    "        results = [[\n",
    "            dataset_str,\n",
    "            Counter(audio_df['dataset']),\n",
    "            Counter(audio_df['classID']),\n",
    "            window_length, 'Whisper',\n",
    "            acc, sen, spe, pre, rec, f1,\n",
    "            roc_auc, pr_auc, cm]]\n",
    "\n",
    "        df_results.append(results)\n",
    "    \n",
    "        test_df['pred'] = all_preds\n",
    "        test_df.to_csv(f'Results_Onset/Model_Whisper_Onset/{dataset_str}/results_test_data_{window_length}s.csv', index=False)\n",
    "        \n",
    "        # Check which data is predicted wrongly\n",
    "        test_df_wrong = test_df[test_df['classID'] != test_df['pred']]\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    df_results.to_csv(f'Results_Onset/Model_Whisper_Onset/{dataset_str}/results_summary_{window_length}s.csv', index=False)\n",
    "    \n",
    "print('All Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for window_length in [0.1, 0.2, 0.3, 0.5, 0.7, 1]:\n",
    "    df_results = []\n",
    "    for datasets_name in list_datasets:\n",
    "        datasets_name.sort()\n",
    "        \n",
    "        dataset_str = '_'.join(datasets_name)\n",
    "    \n",
    "        df = pd.read_csv(f'Results_Onset/Model_Whisper_Onset/{dataset_str}/results_summary_{window_length}s.csv')\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Display or save the result\n",
    "print(combined_df)\n",
    "combined_df.to_csv(f'Results_Onset/Model_Whisper_Onset/{dataset_str}/results_summary_All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
