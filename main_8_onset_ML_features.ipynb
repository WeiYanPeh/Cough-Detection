{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from functions.functions_features import extract_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns\n",
    "columns_features = [\n",
    "    'mean', 'variance', 'std_dev', 'max_value', 'min_value', 'rms',\n",
    "    'skewness', 'kurtosis', 'median', 'range_val', 'iqr',\n",
    "    'zcr', 'energy', 'rmse', 'entropy',\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'spectral_contrast',\n",
    "    'spectral_flatness', 'spectral_rolloff', 'chroma_stft',\n",
    "    ]\n",
    "\n",
    "# MFCC\n",
    "for i in range(1, 21):\n",
    "    columns_features.append(f'mfcc_mean_{i}_mean')\n",
    "    columns_features.append(f'mfcc_{i}_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cough\n",
    "list_dataset_name = [\n",
    "    'coswara', \n",
    "    'coughvid', \n",
    "    'esc50', \n",
    "    'fsdkaggle', \n",
    "    'virufy',\n",
    "    ]\n",
    "\n",
    "overlap=0 # To avoid overfitting when doing kfold\n",
    "\n",
    "if not os.path.exists(f'Results_Onset/Features/ML'):\n",
    "    os.makedirs(f'Results_Onset/Features/ML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ML features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment_length in [0.1, 0.2, 0.3, 0.5, 0.7, 1]:\n",
    "    for dataset_name in list_dataset_name:\n",
    "        print('\\n', dataset_name, segment_length)\n",
    "        \n",
    "        df_all = pd.read_csv(f'Results_Onset/Data_Onset/Annotation/data_summary_{dataset_name}_{segment_length}s_onset_label.csv')\n",
    "        # df_all = df_all[df_all['label']==1].reset_index(drop=True)\n",
    "        df_all['label_onset'] = df_all['label_onset'].apply(ast.literal_eval)\n",
    "        df_all['label_event'] = df_all['label_event'].apply(ast.literal_eval)\n",
    "        df_all = df_all.sample(frac=1).groupby('label').head(1000).reset_index(drop=True)\n",
    "\n",
    "        total_len = len(df_all)\n",
    "        results_all = pd.DataFrame()\n",
    "        path_save = f'Results_Onset/Features/ML/data_extracted_{dataset_name}_{segment_length}s_onset_label.csv'\n",
    "\n",
    "        if os.path.exists(path_save) == False:\n",
    "        \n",
    "            for i in tqdm(range(total_len)):\n",
    "        \n",
    "                filepath = df_all['filepath'][i] # Audio path\n",
    "                dataset = df_all['dataset'][i] # Dataset name\n",
    "                filename = df_all['filename'][i]\n",
    "                \n",
    "                label = df_all['label'][i]\n",
    "                age = df_all['age'][i]\n",
    "                gender = df_all['gender'][i]\n",
    "                status = df_all['status'][i]\n",
    "                label_onset = df_all['label_onset'][i]\n",
    "        \n",
    "                (y, sr) = librosa.load(filepath) # mono=True\n",
    "                duration = librosa.get_duration(y=y, sr=sr)\n",
    "        \n",
    "                segment_samples = int(segment_length * sr)\n",
    "                step = segment_samples - int(overlap * sr)\n",
    "        \n",
    "                results = []\n",
    "        \n",
    "                # Set counter to only process the first 10 0 and 1\n",
    "                counter = {0: 0, 1: 0}\n",
    "                for j in range(0, len(label_onset)):\n",
    "                    if counter[label_onset[j]] < 5:\n",
    "                        start_sample = j * segment_samples\n",
    "                        segment = y[start_sample:start_sample + segment_samples]\n",
    "            \n",
    "                        if len(segment) < segment_samples:\n",
    "                            padding = np.zeros(segment_samples - len(segment))\n",
    "                            segment = np.concatenate((segment, padding))\n",
    "\n",
    "                        mean = np.mean(np.abs(segment))\n",
    "                        \n",
    "                        result_row = extract_features(segment, sr)\n",
    "                        results.append([dataset, filename, filepath, label, age, gender, status, mean, label_onset[j]] + result_row)\n",
    "                        counter[label_onset[j]] += 1\n",
    "                \n",
    "                columns = ['dataset', 'filename', 'filepath', 'label', 'age', 'gender', 'status', 'mean_amplitude', 'label_onset'] + columns_features\n",
    "                results = pd.DataFrame(results, columns=columns)\n",
    "                results_all = pd.concat([results_all, results])\n",
    "            \n",
    "            columns = ['dataset', 'filename', 'filepath', 'label', 'age', 'gender', 'status', 'mean_amplitude', 'label_onset'] + columns_features\n",
    "            results_all = pd.DataFrame(results_all, columns=columns)\n",
    "            results_all.to_csv(path_save, index=False)\n",
    "            print(results_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment_length in [0.1, 0.2, 0.3, 0.5, 0.7, 1]:\n",
    "    print(f'Window length: {segment_length}')\n",
    "    df_all = pd.DataFrame()\n",
    "    for dataset_name in list_dataset_name:\n",
    "        # print(dataset_name)\n",
    "        df = pd.read_csv(f'Results_Onset/Features/ML/data_extracted_{dataset_name}_{segment_length}s_onset_label.csv')\n",
    "        df_all = pd.concat([df_all, df])\n",
    "    \n",
    "    # Extract RMS values\n",
    "    x_non_cough_non_audio = df_all[(df_all['label'] == 0) & (df_all['label_onset'] == 0)]['mean_amplitude'].tolist()\n",
    "    x_non_cough_cough_audio = df_all[(df_all['label'] == 1) & (df_all['label_onset'] == 0)]['mean_amplitude'].tolist()\n",
    "    x_cough_cough_audio = df_all[(df_all['label'] == 1) & (df_all['label_onset'] == 1)]['mean_amplitude'].tolist()\n",
    "    \n",
    "    print(f'x_non_cough_non_audio: {len(x_non_cough_non_audio)}')\n",
    "    print(f'x_non_cough_cough_audio: {len(x_non_cough_cough_audio)}')\n",
    "    print(f'x_cough_cough_audio: {len(x_cough_cough_audio)}')\n",
    "    \n",
    "    # Determine common bin edges\n",
    "    all_rms_values = x_non_cough_non_audio + x_non_cough_cough_audio + x_cough_cough_audio\n",
    "    _, bins = np.histogram(all_rms_values, bins=20)\n",
    "    \n",
    "    # Create 3 horizontal plots with shared x-axis\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharex=True, sharey=True)\n",
    "    \n",
    "    axes[0].hist(x_non_cough_non_audio, bins=bins, color='green', edgecolor='black', \n",
    "                 weights=[100 / len(x_non_cough_non_audio)] * len(x_non_cough_non_audio))\n",
    "    axes[0].set_title(f'(a) Non-Cough (from Non-cough audio)')\n",
    "    axes[0].set_ylabel('Frequency (%)')\n",
    "    \n",
    "    axes[1].hist(x_non_cough_cough_audio, bins=bins, color='red', edgecolor='black', \n",
    "                 weights=[100 / len(x_non_cough_cough_audio)] * len(x_non_cough_cough_audio))\n",
    "    axes[1].set_title(f'(b) Non-Cough (from Cough audio)')\n",
    "    \n",
    "    axes[2].hist(x_cough_cough_audio, bins=bins, color='blue', edgecolor='black', \n",
    "                 weights=[100 / len(x_cough_cough_audio)] * len(x_cough_cough_audio))\n",
    "    axes[2].set_title(f'(c) Cough (from Cough audio)')\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('RMS')\n",
    "        ax.grid(True)\n",
    "        yticks = ax.get_yticks()\n",
    "\n",
    "    plt.title(f'Normalized RMS histogram - Window length: {segment_length}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
