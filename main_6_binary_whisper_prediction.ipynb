{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import datasets\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import json\n",
    "import csv\n",
    "import pathlib\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score\n",
    "    )\n",
    "\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "from transformers import WhisperModel, WhisperFeatureExtractor, AdamW\n",
    "# from transformers import WhisperEncoder\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "from functions_whisper_model import SpeechClassificationDataset, SpeechClassifier, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets = [\n",
    "    # ['fsdkaggle'],    # 2% cough Counter({0: 1570, 1: 30})\n",
    "    # ['virufy'],       # 100% cough Counter({1: 121})\n",
    "    # ['esc50'],        # 2% cough Counter({0: 1960, 1: 40})\n",
    "    # ['coughvid'],     # 30% cough Counter({1: 19777, 0: 10267})\n",
    "    # ['coswara'],      # 25% cough Counter({0: 18914, 1: 5408})\n",
    "    ['coswara', 'coughvid', 'esc50', 'fsdkaggle', 'virufy'], \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "coswara, coughvid, esc50, fsdkaggle, virufy\n",
      "Window Length: 1\n",
      "############################################################\n",
      "(45949, 6)\n",
      "Counter({'coswara': 779, 'coughvid': 734, 'fsdkaggle': 315, 'esc50': 164, 'virufy': 8})\n",
      "Counter({0: 1000, 1: 1000})\n",
      "Train: 1400\n",
      "Val  : 300\n",
      "Test : 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 08:22:37.868920: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-18 08:22:37.879398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-18 08:22:37.895233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-18 08:22:37.899920: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-18 08:22:37.911988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-18 08:22:40.207990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 20/44, Train Loss: 0.5722, Run-time: 109.623s\n",
      "Epoch 1/1, Batch 40/44, Train Loss: 0.3241, Run-time: 103.509s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a8514c927b480aba9c7862ea652c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "Epoch 1/1, Val Loss: 0.2185, Val Accuracy: 0.9467, Val F1: 0.9466, Best Accuracy: 0.9467\n",
      "========================================================================================\n",
      "Total runtime of the program is 271.127s\n",
      "Training Done!\n",
      "Load Whisper Model\n",
      "Evaluate Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9a283462ef4b4593160f83ccb13215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       136\n",
      "           1       0.92      0.93      0.92       164\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.91      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n",
      "ACC: 0.917\n",
      "Test Done!\n",
      "[[122  14]\n",
      " [ 11 153]]\n",
      "\n",
      "############################################################\n",
      "coswara, coughvid, esc50, fsdkaggle, virufy\n",
      "Window Length: 5\n",
      "############################################################\n",
      "(11194, 6)\n",
      "Counter({'coswara': 781, 'coughvid': 674, 'fsdkaggle': 390, 'esc50': 133, 'virufy': 22})\n",
      "Counter({0: 1000, 1: 1000})\n",
      "Train: 1400\n",
      "Val  : 300\n",
      "Test : 300\n",
      "Epoch 1/1, Batch 20/44, Train Loss: 0.5365, Run-time: 102.526s\n",
      "Epoch 1/1, Batch 40/44, Train Loss: 0.1623, Run-time: 102.342s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1dff58b80b486196e70652f7101486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "Epoch 1/1, Val Loss: 0.1980, Val Accuracy: 0.9267, Val F1: 0.9267, Best Accuracy: 0.9267\n",
      "========================================================================================\n",
      "Total runtime of the program is 260.722s\n",
      "Training Done!\n",
      "Load Whisper Model\n",
      "Evaluate Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac83623ccc74cafa090eed578e87fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       148\n",
      "           1       0.91      0.96      0.93       152\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n",
      "ACC: 0.93\n",
      "Test Done!\n",
      "[[133  15]\n",
      " [  6 146]]\n",
      "\n",
      "############################################################\n",
      "coswara, coughvid, esc50, fsdkaggle, virufy\n",
      "Window Length: 10\n",
      "############################################################\n",
      "(7197, 6)\n",
      "Counter({'coswara': 711, 'coughvid': 591, 'fsdkaggle': 420, 'esc50': 227, 'virufy': 51})\n",
      "Counter({0: 1000, 1: 1000})\n",
      "Train: 1400\n",
      "Val  : 300\n",
      "Test : 300\n",
      "Epoch 1/1, Batch 20/44, Train Loss: 0.5656, Run-time: 102.439s\n",
      "Epoch 1/1, Batch 40/44, Train Loss: 0.1782, Run-time: 101.744s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca69281855d4a57a419c35dbd3c46ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "Epoch 1/1, Val Loss: 0.2115, Val Accuracy: 0.9333, Val F1: 0.9333, Best Accuracy: 0.9333\n",
      "========================================================================================\n",
      "Total runtime of the program is 259.123s\n",
      "Training Done!\n",
      "Load Whisper Model\n",
      "Evaluate Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbfa83079c143d18ea5aa39b11cd301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       141\n",
      "           1       0.94      0.96      0.95       159\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n",
      "ACC: 0.95\n",
      "Test Done!\n",
      "[[132   9]\n",
      " [  6 153]]\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "for window_length in [1, 5, 10]:\n",
    "    df_results = []\n",
    "    for datasets_name in list_datasets:\n",
    "        datasets_name.sort()\n",
    "        print('')\n",
    "        print('#'*60)\n",
    "        print(', '.join(datasets_name))\n",
    "        print(f'Window Length: {window_length}')\n",
    "        print('#'*60)\n",
    "        \n",
    "        dataset_str = '_'.join(datasets_name)\n",
    "    \n",
    "        if not os.path.exists(f'Results/Model_Whisper/{dataset_str}'):\n",
    "            os.makedirs(f'Results/Model_Whisper/{dataset_str}')\n",
    "        \n",
    "        path_model_save = f'Results/Model_Whisper/{dataset_str}/whisper_best_model_{window_length}s.pt'\n",
    "\n",
    "        ################################################################\n",
    "        # Load Data\n",
    "        ################################################################\n",
    "        df_all = pd.DataFrame()\n",
    "        for dataset in datasets_name:\n",
    "            df = pd.read_csv(f'Results/Sliced_Wav/dataset_{dataset}_{window_length}s.csv')\n",
    "            df_all = pd.concat([df_all, df], axis=0)\n",
    "        df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "        ################################################################\n",
    "        # Prepare Data\n",
    "        ################################################################\n",
    "        df_all['filepath'] = '/home/l083319/Cough_Related/' + df_all['filepath']\n",
    "        df_all = df_all[df_all['mean_amplitude'] > 0.005].reset_index(drop=True)\n",
    "\n",
    "        for col in ['prob', 'status', 'age', 'Unnamed: 0', 'gender', 'mean_amplitude']:\n",
    "            if col in df_all.columns:\n",
    "                df_all = df_all.drop([col], axis=1)\n",
    "        \n",
    "        audio_df = df_all.rename(columns={\n",
    "            'label': 'classID', \n",
    "            'filepath': 'full_path',\n",
    "        })\n",
    "        \n",
    "        print(audio_df.shape)\n",
    "        audio_df = audio_df.sample(frac=1).groupby('classID').head(1000).reset_index(drop=True)\n",
    "    \n",
    "        print(Counter(audio_df['dataset']))\n",
    "        print(Counter(audio_df['classID']))\n",
    "    \n",
    "        train_df, temp_df = train_test_split(audio_df, test_size=0.3, random_state=42)\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "        \n",
    "        print('Train:', len(train_df))\n",
    "        print('Val  :', len(val_df))\n",
    "        print('Test :', len(test_df))\n",
    "        \n",
    "        train_audio_dataset = datasets.Dataset.from_dict({\n",
    "            \"audio\": train_df[\"full_path\"].tolist(),\n",
    "            \"labels\": train_df[\"classID\"].tolist()    \n",
    "            }).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "        \n",
    "        test_audio_dataset = datasets.Dataset.from_dict({\n",
    "            \"audio\": test_df[\"full_path\"].tolist(),\n",
    "            \"labels\": test_df[\"classID\"].tolist()\n",
    "            }).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "        \n",
    "        val_audio_dataset = datasets.Dataset.from_dict({\n",
    "            \"audio\": val_df[\"full_path\"].tolist(),\n",
    "            \"labels\": val_df[\"classID\"].tolist()\n",
    "            }).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "        ################################################################\n",
    "        # Load Whisper\n",
    "        ################################################################\n",
    "        model_checkpoint = \"openai/whisper-base\"\n",
    "        processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
    "        whisper_model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "        encoder = whisper_model.encoder  # this is the encoder module\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "        train_dataset = SpeechClassificationDataset(train_audio_dataset, processor, encoder)\n",
    "        test_dataset = SpeechClassificationDataset(test_audio_dataset, processor, encoder)\n",
    "        val_dataset = SpeechClassificationDataset(val_audio_dataset, processor, encoder)\n",
    "        \n",
    "        batch_size = 32\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "        num_labels = 2\n",
    "        \n",
    "        model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "        optimizer = AdamW(model.parameters(), lr=2e-5, betas=(0.9, 0.999), eps=1e-08)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "        num_epochs = 1\n",
    "        \n",
    "        # state_dict = torch.load('/home/l083319/Cough_Related/Results/Model/whisper_best_model.pt')\n",
    "        # encoder = WhisperModel.from_pretrained(model_checkpoint)\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # num_labels = 2\n",
    "        # model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "        # model.load_state_dict(state_dict)\n",
    "\n",
    "        ################################################################\n",
    "        # Train Whisper\n",
    "        ################################################################\n",
    "        start = time.time() \n",
    "        train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, path_model_save)\n",
    "        end = time.time() \n",
    "        \n",
    "        print(f\"Total runtime of the program is {round(end - start, 3)}s\") \n",
    "        print('Training Done!')\n",
    "    \n",
    "        ################################################################\n",
    "        # Test Whisper\n",
    "        ################################################################\n",
    "        print('Load Whisper Model')\n",
    "        \n",
    "        state_dict = torch.load(path_model_save)\n",
    "        \n",
    "        # Create a new instance of the model and load the state dictionary\n",
    "        num_labels = 2\n",
    "        model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        print('Evaluate Data')\n",
    "        _, _, _, all_labels, all_preds, all_probs = evaluate(model, test_loader, optimizer, criterion, device)\n",
    "        \n",
    "        print(classification_report(all_labels, all_preds))\n",
    "        print('ACC:', round(accuracy_score(all_labels, all_preds), 3))\n",
    "        print('Test Done!')\n",
    "    \n",
    "    \n",
    "        y_test = all_labels\n",
    "        y_predict = all_preds\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_predict)\n",
    "        cm = confusion_matrix(y_test, y_predict)\n",
    "        print(cm)\n",
    "        \n",
    "        lr_fpr, lr_tpr, _ = roc_curve(y_test, all_probs[:,1])\n",
    "        roc_auc = auc(lr_fpr, lr_tpr)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, all_probs[:,1])\n",
    "        pr_auc = auc(recall, precision)\n",
    "        \n",
    "        pre = precision_score(y_test, y_predict)\n",
    "        rec = recall_score(y_test, y_predict)\n",
    "        f1 = f1_score(y_test, y_predict)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "        spe = tn / (tn + fp)\n",
    "        sen = rec\n",
    "        \n",
    "        columns = ['dataset', 'dataset_counter', 'label_count', 'window_length',\n",
    "                   'model',\n",
    "                   'acc', 'sen', 'spe', 'pre', 'rec', 'f1', 'auc', 'auprc', 'cm']  \n",
    "        \n",
    "        results = [[\n",
    "            dataset_str,\n",
    "            Counter(audio_df['dataset']),\n",
    "            Counter(audio_df['classID']),\n",
    "            window_length, 'Whisper',\n",
    "            acc, sen, spe, pre, rec, f1,\n",
    "            roc_auc, pr_auc, cm]]\n",
    "\n",
    "        df_results.append(results)\n",
    "    \n",
    "        test_df['pred'] = all_preds\n",
    "        test_df.to_csv(f'Results/Model_Whisper/{dataset_str}/results_test_data_{window_length}s.csv', index=False)\n",
    "    \n",
    "        # Check which data is predicted wrongly\n",
    "        test_df_wrong = test_df[test_df['classID'] != test_df['pred']]\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    df_results.to_csv(f'Results/Model_Whisper/{dataset_str}/results_summary_{window_length}s.csv', index=False)\n",
    "    \n",
    "print('All Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   dataset  \\\n",
      "0  coswara_coughvid_esc50_fsdkaggle_virufy   \n",
      "1  coswara_coughvid_esc50_fsdkaggle_virufy   \n",
      "2  coswara_coughvid_esc50_fsdkaggle_virufy   \n",
      "\n",
      "                                     dataset_counter  \\\n",
      "0  Counter({'coswara': 779, 'coughvid': 734, 'fsd...   \n",
      "1  Counter({'coswara': 781, 'coughvid': 674, 'fsd...   \n",
      "2  Counter({'coswara': 711, 'coughvid': 591, 'fsd...   \n",
      "\n",
      "                   label_count  window_length    model       acc       sen  \\\n",
      "0  Counter({0: 1000, 1: 1000})              1  Whisper  0.916667  0.932927   \n",
      "1  Counter({0: 1000, 1: 1000})              5  Whisper  0.930000  0.960526   \n",
      "2  Counter({0: 1000, 1: 1000})             10  Whisper  0.950000  0.962264   \n",
      "\n",
      "        spe       pre       rec        f1       auc     auprc  \\\n",
      "0  0.897059  0.916168  0.932927  0.924471  0.962383  0.967086   \n",
      "1  0.898649  0.906832  0.960526  0.932907  0.981108  0.980885   \n",
      "2  0.936170  0.944444  0.962264  0.953271  0.965610  0.956189   \n",
      "\n",
      "                        cm  \n",
      "0  [[122  14]\\n [ 11 153]]  \n",
      "1  [[133  15]\\n [  6 146]]  \n",
      "2  [[132   9]\\n [  6 153]]  \n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to hold the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for window_length in [1, 5, 10]:\n",
    "    df_results = []\n",
    "    for datasets_name in list_datasets:\n",
    "        datasets_name.sort()\n",
    "        \n",
    "        dataset_str = '_'.join(datasets_name)\n",
    "    \n",
    "        df = pd.read_csv(f'Results/Model_Whisper/{dataset_str}/results_summary_{window_length}s.csv')\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Display or save the result\n",
    "print(combined_df)\n",
    "combined_df.to_csv(f'Results/Model_Whisper/{dataset_str}/results_summary_All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
