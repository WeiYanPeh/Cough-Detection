{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from scipy.signal import resample\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.functions_whisper_model import (SpeechClassifier)   \n",
    "\n",
    "from functions.functions_onset_postprocessing import (\n",
    "    binary_to_intervals, \n",
    "    intervals_to_binary, \n",
    "    merge_close_intervals, \n",
    "    inverse_intervals,\n",
    "    remove_isolated_detection,\n",
    "    fill_short_gaps,\n",
    "    remove_amplitude_threshold,\n",
    "    mean_filter_same_length,\n",
    "    )\n",
    "\n",
    "from functions.functions_onset_metric import (\n",
    "    overlap_calculations, \n",
    "    evaluate_intervals_event_based,\n",
    "    evaluate_intervals_duration_based,\n",
    "    get_average_metrics,\n",
    "    get_sum_metrics,\n",
    "    interval_intersection,\n",
    "    safe_divide,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Default values\n",
    "#################################################################################\n",
    "model_name = 'Whisper'\n",
    "segment_length = 0.2\n",
    "if_plot = True; if_save = False\n",
    "# if_plot = False; if_save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Parameters\n",
    "#################################################################################\n",
    "overlap = 0.5\n",
    "threshold_proba = 0.5\n",
    "threshold_amplitude_mean = 0.005 # Minimum amplitude before drop off\n",
    "threshold_isolate = 1\n",
    "threshold_max_gap = 0.2 # Minimum gap between 2 interval before combination\n",
    "threshold_overlap = 0.1 # Minimum % is required for overlap to be TP\n",
    "threshold_mean_filter = 3\n",
    "step_size = segment_length * (1 - overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Whisper\n",
    "##################################################################################\n",
    "\n",
    "path_model_save = f'models/whisper_best_model_{segment_length}s.pt'\n",
    "model_checkpoint = \"openai/whisper-base\"\n",
    "processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
    "whisper_model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "encoder = whisper_model.encoder  # this is the encoder module\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_labels = 2\n",
    "state_dict = torch.load(path_model_save)\n",
    "model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Input\n",
    "#################################################################################\n",
    "list_filepath = ['data_testing/S001_20260108115951_2026-01-08_11-59_2026-01-08_12-12_1_of_1.m4a']\n",
    "\n",
    "label_onset_manual = [\n",
    "    [5, 6],\n",
    "    [13, 14],\n",
    "    [15, 16],\n",
    "    [29, 30],\n",
    "    [38, 39],\n",
    "    [40, 42],\n",
    "    [49, 50],\n",
    "    [63, 64],\n",
    "    [66, 67],\n",
    "    [79, 80],\n",
    "    [82, 83],\n",
    "    [197, 199],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Main\n",
    "#################################################################################\n",
    "def plot_intervals(ax, intervals, y, color, label=None):\n",
    "    for start, end in intervals:\n",
    "        ax.barh(y=y, width=end - start, left=start, height=0.2, color=color, label=label)\n",
    "        \n",
    "# Function to compute intersection of two interval lists\n",
    "def compute_intersection(intervals1, intervals2):\n",
    "    result = []\n",
    "    for start1, end1 in intervals1:\n",
    "        for start2, end2 in intervals2:\n",
    "            start = max(start1, start2)\n",
    "            end = min(end1, end2)\n",
    "            if start < end:  # valid overlap\n",
    "                result.append([start, end])\n",
    "    return result\n",
    "\n",
    "results_all = []\n",
    "for filepath in tqdm(list_filepath):\n",
    "\n",
    "    filename = filepath.split('/')[-1]\n",
    "    print(filename)\n",
    "\n",
    "    # Load data\n",
    "    # (y, sr) = librosa.load(filepath, duration=180) # mono=True\n",
    "    (y, sr) = librosa.load(filepath) # mono=True\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "    # Get time interval\n",
    "    time_intervals = np.arange(0, duration - segment_length + 2*step_size, step_size)\n",
    "\n",
    "    if if_plot == True:\n",
    "        print('Duration:', duration)\n",
    "        # print('Time:', time_intervals)\n",
    "    \n",
    "    segment_samples = int(segment_length * sr)\n",
    "    step = segment_samples * (1 - overlap)\n",
    "\n",
    "    label_onset = [0 for i in range(len(time_intervals))]\n",
    "\n",
    "    label_pred = []\n",
    "    label_pred_proba = []\n",
    "    list_threshold_amplitude_mean = []\n",
    "\n",
    "    #################################################################################\n",
    "    # Looping through segments\n",
    "    #################################################################################\n",
    "    if len(label_onset) != 0:\n",
    "        # for start_sample in np.arange(0, len(y) - step, step):\n",
    "        for start_sample in tqdm(np.arange(0, len(y), step), position=0, leave=True):\n",
    "            start_sample = int(start_sample)  # convert to int index\n",
    "            segment = y[start_sample:start_sample + segment_samples]\n",
    "\n",
    "            if len(segment) < segment_samples:\n",
    "                padding = np.zeros(segment_samples - len(segment))\n",
    "                segment = np.concatenate((segment, padding))\n",
    "\n",
    "            amplitude_mean = np.mean(np.abs(segment))\n",
    "            \n",
    "            #################################################################################\n",
    "            # Extract Features and predict\n",
    "            #################################################################################\n",
    "            if amplitude_mean <= threshold_amplitude_mean:\n",
    "                list_threshold_amplitude_mean.append(0)\n",
    "            else:\n",
    "                list_threshold_amplitude_mean.append(1)\n",
    "                \n",
    "            #################################################################################\n",
    "            # Get probabilities\n",
    "            #################################################################################\n",
    "            if amplitude_mean <= threshold_amplitude_mean:\n",
    "                pred_proba = np.array([1, 0])\n",
    "                pred = 0\n",
    "            \n",
    "            else:\n",
    "                # Whisper               \n",
    "                new_length = int(len(segment) * 16000 / 22500)\n",
    "                segment = resample(segment, new_length)\n",
    "                \n",
    "                segment_np = segment.astype(np.float32)\n",
    "                inputs = processor(segment_np, sampling_rate=16000, return_tensors=\"pt\")\n",
    "                input_features = inputs.input_features.to(device)\n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    logits = model(input_features)\n",
    "                    probabilities = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "                    pred = int(probabilities[1] >= threshold_proba)\n",
    "                    pred_proba = probabilities\n",
    "\n",
    "            label_pred.append(pred)\n",
    "            label_pred_proba.append(pred_proba)\n",
    "\n",
    "        label_pred_proba = np.array(label_pred_proba)\n",
    "        label_pred_proba = label_pred_proba[:, 1]\n",
    "        \n",
    "        # Preprocessing\n",
    "        label_pred_proba_raw = label_pred_proba.copy() # Keep copy of raw signal\n",
    "        for _ in range(5):\n",
    "            label_pred_proba = mean_filter_same_length(label_pred_proba, threshold_mean_filter) # Smoothen signal\n",
    "        label_pred = (np.array(label_pred_proba) >= threshold_proba).astype(int) # Get binary outputs\n",
    "        \n",
    "        label_pred = remove_amplitude_threshold(label_pred, list_threshold_amplitude_mean) # Drop low amplitudes -> Was commented in OG\n",
    "        label_pred = fill_short_gaps(label_pred, threshold=1) # Fill in short gaps -> Was commented in OG\n",
    "        label_pred = remove_isolated_detection(label_pred, max_length_sequence=threshold_isolate) # Remove isolated detection -> Was commented in OG\n",
    "\n",
    "        # Convert into intervals\n",
    "        # label_onset_interval = binary_to_intervals(label_onset, time_step=segment_length) # Onset so no overlap\n",
    "        label_onset_interval = label_onset_manual.copy()\n",
    "        label_pred_interval = binary_to_intervals(label_pred, time_step=step_size) # Pred so overlap\n",
    "        \n",
    "        label_pred_interval = merge_close_intervals(label_pred_interval, threshold_max_gap) # Merge close intervals\n",
    "        label_cough_interval_intersect = interval_intersection(label_onset_interval, label_pred_interval)\n",
    "        \n",
    "        # Convert back\n",
    "        label_onset = intervals_to_binary(label_onset_interval, len(label_onset), segment_length) # Onset so no overlap\n",
    "        label_pred = intervals_to_binary(label_pred_interval, len(label_pred), step_size) # Pred so overlap\n",
    "\n",
    "        audio_information = {\n",
    "            'filepath': filepath,\n",
    "            'filename': filename,\n",
    "            'label': 1,\n",
    "            'segment_length': segment_length,\n",
    "            'overlap': overlap,\n",
    "            'label_onset': label_onset,\n",
    "            'label_pred': label_pred,\n",
    "            'len': len(label_onset),\n",
    "            'duration': duration,\n",
    "            'threshold_proba': threshold_proba,\n",
    "            'threshold_amplitude_mean': threshold_amplitude_mean,\n",
    "            'threshold_overlap': threshold_overlap,\n",
    "            'threshold_max_gap': threshold_max_gap,\n",
    "            'label_onset_interval': label_onset_interval,\n",
    "            'label_pred_interval': label_pred_interval,\n",
    "        }\n",
    "        \n",
    "        metrics_event = evaluate_intervals_event_based(label_pred_interval, label_onset_interval, duration, overlap_threshold=threshold_overlap)\n",
    "        metrics_duration = evaluate_intervals_duration_based(label_pred_interval, label_onset_interval, duration)\n",
    "        metrices_combined = {**audio_information, **metrics_event, **metrics_duration}\n",
    "\n",
    "        if if_plot == True:\n",
    "            list_print = ['label_onset_interval', 'label_pred_interval', 'SEN_d', 'SPE_d', 'PRE_d', 'F1_d', 'FAR_d', 'PRE_e', 'REC_e', 'F1_e', 'FAR_e']\n",
    "            for key in list_print:\n",
    "                print(f'{key}: {metrices_combined[key]}')\n",
    "\n",
    "        results_all.append(metrices_combined)\n",
    "\n",
    "        if if_plot == True:\n",
    "            # Create a figure with subplots\n",
    "            fig, axs = plt.subplots(3, 1, figsize=(18, 5), sharex=True)\n",
    "            \n",
    "            # Plot waveform\n",
    "            librosa.display.waveshow(y, sr=sr, ax=axs[0])\n",
    "            axs[0].set_title('Audio Waveform')\n",
    "            axs[0].set_xlabel('')\n",
    "            axs[0].set_ylabel('Amplitude')\n",
    "            axs[0].grid(True)\n",
    "            axs[0].minorticks_on()  # Enable minor ticks for finer control\n",
    "    \n",
    "            # Plot waveform\n",
    "            time_intervals =np.linspace(0, duration, len(label_pred_proba), endpoint=False)\n",
    "            axs[1].plot(time_intervals, label_pred_proba, color='green', marker='o')\n",
    "            axs[1].axhline(y=threshold_proba, linestyle=':', color='black')  # dotted horizontal line at y=0.5\n",
    "            axs[1].set_ylim(-0.1, 1.1)\n",
    "            axs[1].set_title('Prediction Probability')\n",
    "            axs[1].set_ylabel('Probability')\n",
    "  \n",
    "            # Plot onset (red), pred (blue), and intersection (purple)\n",
    "            plot_intervals(axs[2], label_onset_interval, y=0.8, color='red', label='True')\n",
    "            plot_intervals(axs[2], label_pred_interval, y=0.5, color='green', label='Predict')\n",
    "            plot_intervals(axs[2], label_cough_interval_intersect, y=0.2, color='black', label='Intersect')\n",
    "\n",
    "            # Add vertical lines every minute (60 seconds)\n",
    "            minute_marks = np.arange(0, duration + 30, 30)\n",
    "            \n",
    "            for t in minute_marks:\n",
    "                axs[2].axvline(x=t, color='gray', linestyle='--', alpha=0.4)\n",
    "            \n",
    "            axs[2].set_title('Prediction vs True Labels')\n",
    "            axs[2].set_ylim(0.05, 0.95)\n",
    "            axs[2].set_yticks([0.2, 0.5, 0.8])\n",
    "            axs[2].set_yticklabels(['Intersect', 'Predict', 'True'])\n",
    "            axs[2].set_xlabel('Time (s)')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "            # Play audio\n",
    "            display(Audio(data=y, rate=sr))\n",
    "\n",
    "if not os.path.exists(f'data_testing_results'):\n",
    "    os.makedirs(f'data_testing_results')\n",
    "results_all = pd.DataFrame(results_all, columns=metrices_combined.keys())\n",
    "\n",
    "if if_save == True:\n",
    "    results_all.to_csv(f'data_testing_results/results_onset_metrics_{segment_length}s_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
