{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ast\n",
    "import joblib\n",
    "import joblib\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import resample\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from transformers import WhisperFeatureExtractor, WhisperModel, WhisperProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.functions_model import get_CNN_model, get_NN_model\n",
    "from functions.functions_features import extract_features, extract_features_CNN\n",
    "from functions.functions_whisper_model import SpeechClassificationDataset, SpeechClassifier, train, evaluate\n",
    "from functions.functions_onset_metric import (\n",
    "    binary_to_intervals, intervals_to_binary, \n",
    "    merge_close_intervals, \n",
    "    compute_overlap, \n",
    "    total_overlap_duration,\n",
    "    subtract_intervals, \n",
    "    total_duration, \n",
    "    overlap_calculations, \n",
    "    interval_intersection,\n",
    "    total_interval_duration,\n",
    "    compute_overlap, \n",
    "    inverse_intervals,\n",
    "    evaluate_intervals,\n",
    "    remove_isolated_detection,\n",
    "    fill_short_gaps,\n",
    "    remove_mean_threshold,\n",
    "    safe_divide,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns\n",
    "columns_features = [\n",
    "    'mean', 'variance', 'std_dev', 'max_value', 'min_value', 'rms',\n",
    "    'skewness', 'kurtosis', 'median', 'range_val', 'iqr',\n",
    "    'zcr', 'energy', 'rmse', 'entropy',\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'spectral_contrast',\n",
    "    'spectral_flatness', 'spectral_rolloff', 'chroma_stft',\n",
    "    ]\n",
    "\n",
    "# MFCC\n",
    "for i in range(1, 21):\n",
    "    columns_features.append(f'mfcc_mean_{i}_mean')\n",
    "    columns_features.append(f'mfcc_{i}_std')\n",
    "\n",
    "column_drop = ['mean', 'variance', 'std_dev', 'skewness', 'kurtosis', 'median', 'range_val', 'iqr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [[0.7, 0.8], [1.0, 1.2], [5, 5.5], [6, 7], [10, 12]]\n",
    "print(merge_close_intervals(intervals, max_gap=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example intervals\n",
    "# predicted_intervals = [[1, 4], [8, 11], [40, 45], [46, 50]]\n",
    "# ground_truth_intervals = [[2, 5], [9, 12], [39, 44], [50, 54]]\n",
    "\n",
    "# metrics_overlap = overlap_calculations(predicted_intervals, ground_truth_intervals)\n",
    "# for key, value in metrics_overlap.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[1, 3], [5, 7]]\n",
    "duration = 10\n",
    "print(inverse_intervals(labels, duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example intervals\n",
    "predicted_intervals = [[1, 4], [7, 10]]\n",
    "ground_truth_intervals = [[2, 5], [8, 9]]\n",
    "\n",
    "metrics_overlap = overlap_calculations(predicted_intervals, ground_truth_intervals)\n",
    "for key, value in metrics_overlap.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# predicted_intervals = [[1, 4], [8, 11], [40, 45], [46, 50]]\n",
    "# ground_truth_intervals = [[2, 5], [9, 12], [39, 44], [50, 54]]\n",
    "\n",
    "# Example usage\n",
    "predicted_intervals = [[1, 5], [15, 20]]\n",
    "ground_truth_intervals = [[0, 20]]\n",
    "threshold_overlap = 0.1  # 10% overlap required\n",
    "\n",
    "metrics = evaluate_intervals(predicted_intervals, ground_truth_intervals, overlap_threshold=threshold_overlap)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset_name = [\n",
    "    'coswara', \n",
    "    'coughvid', \n",
    "    'esc50', \n",
    "    'fsdkaggle', \n",
    "    'virufy',\n",
    "    ]\n",
    "\n",
    "#################################################################################\n",
    "# Default values\n",
    "#################################################################################\n",
    "segment_length = 0.3 # [0.1, 0.2, 0.3, 0.5, 0.7, 1] Segment split window length\n",
    "overlap = 0 # Overlap % (in fraction)\n",
    "step_size = segment_length * (1 - overlap)\n",
    "\n",
    "threshold_proba = 0.5 # Probability threshold for model prediction\n",
    "threshold_amplitude_mean = 0.005 # Minimum amplitude before drop off\n",
    "threshold_max_gap = 0.2 # Minimum gap between 2 interval before combination\n",
    "\n",
    "threshold_overlap = 0.1 # Minimum % is required for overlap to be TP\n",
    "\n",
    "dataset_str = '_'.join(list_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'LR' # RF, GB, LR\n",
    "# model_name = 'RF', # GB, LR\n",
    "# model_name = 'Keras_NN'\n",
    "# model_name = 'CNN'\n",
    "model_name = 'Whisper'\n",
    "\n",
    "if model_name in ['LR', 'DT', 'RF', 'SVM', 'KNN', 'NB', 'NN', 'GB']:\n",
    "    #################################################################################\n",
    "    # ML\n",
    "    #################################################################################\n",
    "    print(f'ML: {model_name}')\n",
    "    path_model_save = f'Results_Onset/Model_Onset/{dataset_str}/{model_name}_{segment_length}s/'\n",
    "    model_filename = f\"{path_model_save}model_1.joblib\"\n",
    "    scaler_filename = f\"{path_model_save}scaler__1.joblib\"\n",
    "    model = joblib.load(model_filename)\n",
    "    scaler = joblib.load(scaler_filename)\n",
    "\n",
    "elif model_name in ['NN']:\n",
    "    ##################################################################################\n",
    "    # NN\n",
    "    ##################################################################################\n",
    "    path_model_save = f'Results_Onset/Model_Onset/{dataset_str}/Keras_NN_{segment_length}s/'\n",
    "    model = get_NN_model(53)\n",
    "    model.load_weights(f'{path_model_save}model_1.h5')\n",
    "    scaler_filename = f\"{path_model_save}scaler__1.joblib\"\n",
    "    scaler = joblib.load(scaler_filename)\n",
    "\n",
    "elif model_name in ['CNN']:\n",
    "    #################################################################################\n",
    "    # CNN\n",
    "    #################################################################################    \n",
    "    dimension_dictionary = {\n",
    "        0.1: 5,\n",
    "        0.2: 9,\n",
    "        0.3: 13,\n",
    "        0.5: 22,\n",
    "        0.7: 31,\n",
    "        1: 22,\n",
    "    }\n",
    "    \n",
    "    dim_first = 128\n",
    "    input_shape = (dim_first, dimension_dictionary[segment_length], 1)\n",
    "    model = get_CNN_model(input_shape)\n",
    "    \n",
    "    path_model_save = f'Results_Onset/Model_CNN_Onset/{dataset_str}/{segment_length}s/'\n",
    "    model.load_weights(f'{path_model_save}model_CNN_{segment_length}s_1.h5')\n",
    "    scaler_filename = f\"{path_model_save}scaler_pipeline_CNN_{segment_length}s_1.joblib\"\n",
    "    scaler = joblib.load(scaler_filename)\n",
    "\n",
    "elif model_name in ['Whisper']:\n",
    "    ##################################################################################\n",
    "    # Whisper\n",
    "    ##################################################################################\n",
    "    path_model_save = f'Results_Onset/Model_Whisper_Onset/{dataset_str}/whisper_best_model_{segment_length}s.pt'\n",
    "    \n",
    "    model_checkpoint = \"openai/whisper-base\"\n",
    "    processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
    "    whisper_model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
    "    encoder = whisper_model.encoder  # this is the encoder module\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    num_labels = 2\n",
    "    state_dict = torch.load(path_model_save)\n",
    "    model = SpeechClassifier(num_labels, encoder).to(device)\n",
    "    model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Main\n",
    "#################################################################################\n",
    "results_all = []\n",
    "for dataset_name in list_dataset_name:\n",
    "    print(dataset_name)\n",
    "\n",
    "    df_all = pd.read_csv(f'Results_Onset/Data_Onset/Annotation/data_summary_{dataset_name}_{segment_length}s_onset_label.csv')\n",
    "    df_all['label_onset'] = df_all['label_onset'].apply(ast.literal_eval)\n",
    "    df_all['label_event'] = df_all['label_event'].apply(ast.literal_eval)\n",
    "    \n",
    "    df_all = df_all[df_all['label']==0].reset_index(drop=True)\n",
    "    # df_all = df_all[df_all['label']==1].reset_index(drop=True)\n",
    "    \n",
    "    total_len = len(df_all)\n",
    "    if total_len > 1:\n",
    "        total_len = 20\n",
    "\n",
    "    for i in tqdm(range(total_len)):\n",
    "\n",
    "        filepath = df_all['filepath'][i] # Audio path\n",
    "        dataset = df_all['dataset'][i] # Dataset name\n",
    "        filename = df_all['filename'][i]\n",
    "        \n",
    "        label = df_all['label'][i]\n",
    "        age = df_all['age'][i]\n",
    "        gender = df_all['gender'][i]\n",
    "        status = df_all['status'][i]\n",
    "        \n",
    "        # print(f'{dataset} {filename} {label}')\n",
    "\n",
    "        # Load data\n",
    "        (y, sr) = librosa.load(filepath) # mono=True\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        # Get time interval\n",
    "        time_intervals = np.arange(0, duration - segment_length + step_size, step_size)\n",
    "        print('Duration:', duration)\n",
    "        print('Time:', time_intervals)\n",
    "\n",
    "        segment_samples = int(segment_length * sr)\n",
    "        step = segment_samples - int(overlap * sr)\n",
    "\n",
    "        try:\n",
    "            label_onset = df_all['label_onset'][i]\n",
    "            label_onset = list(label_onset)\n",
    "        except:\n",
    "            label_onset = [0 for i in range(len(time_intervals))]\n",
    "\n",
    "        label_pred = []\n",
    "        label_pred_proba = []\n",
    "        list_threshold_amplitude_mean = []\n",
    "\n",
    "        #################################################################################\n",
    "        # Looping through segments\n",
    "        #################################################################################\n",
    "        if len(label_onset) != 0:\n",
    "            for j in range(0, len(label_onset)):\n",
    "                start_sample = j * segment_samples\n",
    "                segment = y[start_sample:start_sample + segment_samples]\n",
    "    \n",
    "                if len(segment) < segment_samples:\n",
    "                    padding = np.zeros(segment_samples - len(segment))\n",
    "                    segment = np.concatenate((segment, padding))\n",
    "\n",
    "                mean = np.mean(np.abs(segment))\n",
    "                \n",
    "                #################################################################################\n",
    "                # Extract Features and predict\n",
    "                #################################################################################\n",
    "                if mean <= threshold_amplitude_mean:\n",
    "                    list_threshold_amplitude_mean.append(0)\n",
    "                else:\n",
    "                    list_threshold_amplitude_mean.append(1)\n",
    "                    \n",
    "                #################################################################################\n",
    "                # Get probabilities\n",
    "                #################################################################################\n",
    "                # Whisper\n",
    "                if model_name == 'Whisper':                    \n",
    "                    # Calculate new number of samples\n",
    "                    new_length = int(len(segment) * 16000 / 22500)\n",
    "                    segment = resample(segment, new_length)\n",
    "                    \n",
    "                    segment_np = segment.astype(np.float32)\n",
    "                    inputs = processor(segment_np, sampling_rate=16000, return_tensors=\"pt\")\n",
    "                    input_features = inputs.input_features.to(device)\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                        logits = model(input_features)\n",
    "                        probabilities = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "                        pred = np.argmax(probabilities)\n",
    "                        pred_proba = probabilities\n",
    "\n",
    "                # CNN\n",
    "                elif model_name == 'CNN':\n",
    "                    result_row = extract_features_CNN(segment, sr, segment_length)\n",
    "                    result_row = np.array(result_row[0]).reshape((1, dim_first,  dimension_dictionary[segment_length]))\n",
    "                    result_row = result_row[..., np.newaxis]\n",
    "\n",
    "                    result_row = np.array(result_row)\n",
    "                    result_row = np.nan_to_num(result_row, nan=0)\n",
    "\n",
    "                    pred_proba = model.predict(result_row, verbose=0)[0]\n",
    "                    pred = np.argmax(pred_proba)\n",
    "                    # pred = pred_proba[1]\n",
    "\n",
    "                # ML / NN\n",
    "                elif model_name in ['LR', 'DT', 'RF', 'SVM', 'KNN', 'NB', 'NN', 'GB', 'Keras_NN']:\n",
    "                    result_row = extract_features(segment, sr)\n",
    "                    result_row = pd.DataFrame([result_row], columns=columns_features)\n",
    "                    for col in column_drop:\n",
    "                        if col in result_row.columns:\n",
    "                            result_row = result_row.drop([col], axis=1)\n",
    "                    result_row = np.array(result_row)[0]\n",
    "                    result_row = np.nan_to_num(result_row, nan=0)\n",
    "                    result_row = scaler.transform(result_row.reshape(1, -1))\n",
    "\n",
    "                    # NN\n",
    "                    if model_name in ['Keras_NN']:\n",
    "                        pred_proba = model.predict(result_row)\n",
    "                        pred = np.argmax(pred_proba, axis=1)\n",
    "\n",
    "                    # ML\n",
    "                    else:\n",
    "                        pred_proba = model.predict_proba(result_row)\n",
    "                        # label_pred = np.argmax(pred_proba, axis=1)\n",
    "                        pred = (pred_proba[:, 1] >= threshold_proba).astype(int)[0]\n",
    "                        pred_proba = list(pred_proba[0])\n",
    "\n",
    "                label_pred.append(pred)\n",
    "                label_pred_proba.append(pred_proba)\n",
    "\n",
    "            label_pred_proba = np.array(label_pred_proba)\n",
    "            print('True:', label_onset)\n",
    "            print('Pred:', label_pred)\n",
    "\n",
    "            # Preprocessing\n",
    "            label_pred = remove_mean_threshold(label_pred, list_threshold_amplitude_mean)\n",
    "            label_pred = fill_short_gaps(label_pred, threshold=1)\n",
    "            label_pred = remove_isolated_detection(label_pred, max_length_sequence=1) # Remove isolated detection\n",
    "\n",
    "            # Convert into intervals\n",
    "            label_onset_interval = binary_to_intervals(label_onset, time_step=segment_length)\n",
    "            label_pred_interval = binary_to_intervals(label_pred, time_step=segment_length)\n",
    "            \n",
    "            label_pred_interval = merge_close_intervals(label_pred_interval, threshold_max_gap) # Merge close intervals\n",
    "            \n",
    "            # Convert back\n",
    "            label_pred = intervals_to_binary(label_pred_interval, len(label_pred))\n",
    "            label_onset = intervals_to_binary(label_onset_interval, len(label_onset))\n",
    "\n",
    "            # Get non-cough intervals\n",
    "            label_onset_inv_interval = inverse_intervals(label_onset_interval, duration)\n",
    "            label_pred_inv_interval = inverse_intervals(label_pred_interval, duration)\n",
    "\n",
    "            # Get cough and non-cough intersects\n",
    "            label_cough_interval_intersect = interval_intersection(label_onset_interval, label_pred_interval)\n",
    "            label_non_cough_interval_intersect = interval_intersection(label_onset_inv_interval, label_pred_inv_interval)\n",
    "\n",
    "            # Get intersection duration\n",
    "            total_cough_intersect_duration = round(total_interval_duration(label_cough_interval_intersect), 1)\n",
    "            total_non_cough_intersect_duration = round(total_interval_duration(label_non_cough_interval_intersect), 1)\n",
    "\n",
    "            total_non_cough_duration = round(total_interval_duration(label_onset_inv_interval), 1)\n",
    "            total_cough_duration = round(total_interval_duration(label_onset_interval), 1)\n",
    "            total_pred_duration = round(total_interval_duration(label_pred_interval), 1)\n",
    "\n",
    "            SENd = round(safe_divide(total_cough_intersect_duration, total_cough_duration), 3)\n",
    "            SPEd = round(safe_divide(total_non_cough_intersect_duration, total_non_cough_duration), 3)\n",
    "            PREd = round(safe_divide(total_cough_intersect_duration, total_pred_duration), 3)\n",
    "            F1d = round(2 * safe_divide((PREd * SENd), (PREd + SENd)), 3)\n",
    "            \n",
    "            audio_information = {\n",
    "                'filepath': filepath,\n",
    "                'dataset': dataset,\n",
    "                'filename': filename,\n",
    "                'label': label,\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'status': status,\n",
    "                'segment_length': segment_length,\n",
    "                'overlap': overlap,\n",
    "                'label_onset': label_onset,\n",
    "                'label_pred': label_pred,\n",
    "                'len': len(label_onset),\n",
    "                'duration': len(label_onset)*segment_length,\n",
    "                'threshold_proba': threshold_proba,\n",
    "                'threshold_amplitude_mean': threshold_amplitude_mean,\n",
    "                'threshold_overlap': threshold_overlap,\n",
    "                'threshold_max_gap': threshold_max_gap,\n",
    "                'label_onset_interval': label_onset_interval,\n",
    "                'label_pred_interval': label_pred_interval,\n",
    "                'label_onset_inv_interval': label_onset_inv_interval,\n",
    "                'label_pred_inv_interval': label_pred_inv_interval,\n",
    "                'label_cough_interval_intersect': label_cough_interval_intersect,\n",
    "                'label_non_cough_interval_intersect': label_non_cough_interval_intersect,\n",
    "                'total_cough_intersect_duration': total_cough_intersect_duration,\n",
    "                'total_non_cough_intersect_duration': total_non_cough_intersect_duration,\n",
    "                'total_cough_duration': total_cough_duration,\n",
    "                'total_non_cough_duration': total_non_cough_duration,\n",
    "                'total_pred_duration': total_pred_duration,\n",
    "                'SENd': SENd,\n",
    "                'SPEd': SPEd,\n",
    "                'PREd': PREd,\n",
    "                'F1d': F1d,\n",
    "            }\n",
    "            \n",
    "            metrics = evaluate_intervals(\n",
    "                label_pred_interval, \n",
    "                label_onset_interval, \n",
    "                overlap_threshold=threshold_overlap)\n",
    "    \n",
    "    \n",
    "            metrices_combined = {**audio_information, **metrics}\n",
    "            # for key, value in metrices_combined.items():\n",
    "            #     print(f\"{key}: {value}\")\n",
    "\n",
    "            list_print = [\n",
    "                'label_onset_interval', 'label_pred_interval',\n",
    "                # 'label_onset_inv_interval', 'label_pred_inv_interval',\n",
    "                # 'label_cough_intersect', 'label_non_cough_intersect',\n",
    "                # 'TP', 'FP', 'FN', 'PRE', 'REC', 'F1',\n",
    "                'total_cough_intersect_duration', \n",
    "                'total_non_cough_intersect_duration',\n",
    "                'total_cough_duration', 'total_non_cough_duration', 'total_pred_duration',\n",
    "                \n",
    "                'SENd', 'SPEd', 'PREd', 'F1d',\n",
    "                ]\n",
    "            for key in list_print:\n",
    "                print(f'{key}: {metrices_combined[key]}')\n",
    "\n",
    "            results_all.append(metrices_combined)\n",
    "            \n",
    "            # Create a figure with subplots\n",
    "            fig, axs = plt.subplots(3, 1, figsize=(6, 5), \n",
    "                                    sharex=True\n",
    "                                   )\n",
    "            \n",
    "            # Plot waveform\n",
    "            librosa.display.waveshow(y, sr=sr, ax=axs[0])\n",
    "            axs[0].set_title('Audio Waveform')\n",
    "            axs[0].set_xlabel('Time (s)')\n",
    "            axs[0].set_ylabel('Amplitude')\n",
    "            axs[0].grid(True)\n",
    "            axs[0].minorticks_on()  # Enable minor ticks for finer control\n",
    "    \n",
    "            # Plot waveform\n",
    "            axs[1].plot(time_intervals, label_pred_proba[:, 1], color='green', marker='o')\n",
    "            axs[1].axhline(y=threshold_proba, linestyle=':', color='black')  # dotted horizontal line at y=0.5\n",
    "            axs[1].set_ylim(0, 1.1)\n",
    "            axs[1].set_title('Predict Probability')\n",
    "            axs[1].set_ylabel('Values')\n",
    "            \n",
    "\n",
    "            def plot_intervals(ax, intervals, y, color, label=None):\n",
    "                for start, end in intervals:\n",
    "                    ax.barh(y=y, width=end - start, left=start, height=0.2, color=color, label=label)\n",
    "                    \n",
    "            # Function to compute intersection of two interval lists\n",
    "            def compute_intersection(intervals1, intervals2):\n",
    "                result = []\n",
    "                for start1, end1 in intervals1:\n",
    "                    for start2, end2 in intervals2:\n",
    "                        start = max(start1, start2)\n",
    "                        end = min(end1, end2)\n",
    "                        if start < end:  # valid overlap\n",
    "                            result.append([start, end])\n",
    "                return result\n",
    "                \n",
    "            # Plot onset (red), pred (blue), and intersection (purple)\n",
    "            plot_intervals(axs[2], label_onset_interval, y=0.8, color='red', label='True')\n",
    "            plot_intervals(axs[2], label_pred_interval, y=0.5, color='green', label='Predict')\n",
    "            plot_intervals(axs[2], label_cough_interval_intersect, y=0.2, color='black', label='Intersect')\n",
    "\n",
    "            axs[2].set_title('Prediction vs True Labels')\n",
    "            axs[2].set_ylim(0, 1)\n",
    "            axs[2].set_yticks([0.2, 0.5, 0.8])\n",
    "            axs[2].set_yticklabels(['Intersect', 'Predict', 'True'])\n",
    "            axs[2].set_xlabel('Time (s)')\n",
    "\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "            # Play audio\n",
    "            display(Audio(data=y, rate=sr))\n",
    "\n",
    "results_all = pd.DataFrame(results_all, columns=metrices_combined.keys())\n",
    "results_all.to_csv(f'Results_Onset/results_onset_metrics_{segment_length}s.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = pd.DataFrame(results_all, columns=metrices_combined.keys())\n",
    "results_all.to_csv('Results_Onset/results_onset_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
